# -*- coding: utf-8 -*-
"""voice-filter.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ekMhvwAEPI0stPRkoodLUlqX9LFuoObf
"""

!git clone https://github.com/nguyenvulebinh/voice-filter.git

# Commented out IPython magic to ensure Python compatibility.
# %cd voice-filter

# !pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu117
# !pip install -r requirements.txt

from src.model.modeling_enh import VoiceFilter
import torch
from huggingface_hub import hf_hub_download
import os
import glob
import csv
from tqdm import tqdm
import librosa
import numpy as np
import soundfile as sf

use_gpu = True
if use_gpu:
    if not torch.cuda.is_available():
        use_gpu = False

def cal_xvector_sincnet_embedding(xvector_model, ref_wav, max_length=5, sr=16000):
    wavs = []
    for i in range(0, len(ref_wav), max_length*sr):
        wav = ref_wav[i:i + max_length*sr]
        wav = np.concatenate([wav, np.zeros(max(0, max_length * sr - len(wav)))])
        wavs.append(wav)
    wavs = torch.from_numpy(np.stack(wavs))
    if use_gpu:
        wavs = wavs.cuda()
    embed = xvector_model(wavs.unsqueeze(1).float())
    return torch.mean(embed, dim=0).detach().cpu()

# Load models
repo_id = 'nguyenvulebinh/voice-filter'
enh_model = VoiceFilter.from_pretrained(repo_id, cache_dir='/content/voice-filter/cache')
if use_gpu:
    enh_model = enh_model.cuda()

"""# Voice filter only with reference audio"""

# Load some audio sample
mix_wav_path = hf_hub_download(repo_id=repo_id, filename="binh_linh_newspaper_music_noise.wav", cache_dir='/content/voice-filter/cache')
mix_wav_path = './binh-linh.wav'
ref_wav_path = hf_hub_download(repo_id=repo_id, filename="binh_ref_long.wav", cache_dir='/content/voice-filter/cache')
# ref_wav_path = hf_hub_download(repo_id=repo_id, filename="linh_ref_long.wav", cache_dir='/content/voice-filter/cache')
output_wav_path = "output.wav"
mixed_wav, _ = librosa.load(mix_wav_path, sr=16000)
ref_wav, _ = librosa.load(ref_wav_path, sr=16000)

# Calculate target speaker embedding
xvector = cal_xvector_sincnet_embedding(enh_model.xvector_model, ref_wav)
# Speech enhancing
max_amp = np.abs(mixed_wav).max()
mix_scaling = 1 / max_amp
mixed_wav = mix_scaling * mixed_wav
mixed_wav_tf = torch.from_numpy(mixed_wav)
if use_gpu:
    mixed_wav_tf = mixed_wav_tf.cuda()
    xvector= xvector.cuda()
est_wav = enh_model.do_enh(mixed_wav_tf, xvector).cpu().detach().numpy()
# Normalize estimated wav
max_amp = np.abs(est_wav).max()
mix_scaling = 1 / max_amp
est_wav = mix_scaling * est_wav
# write output file
sf.write(output_wav_path, est_wav, 16000)

import torch

torch.__version__

"""### Play audio"""

import IPython

"""Noisy audio"""

IPython.display.Audio(data=mixed_wav, rate=16000)

"""Reference audio"""

IPython.display.Audio(data=ref_wav, rate=16000)

"""Voice filter output"""

IPython.display.Audio(data=est_wav, rate=16000)

"""# Voice filter only without reference audio
Work only if having one dominant voice inside the audio
"""

# Load some audio sample
mix_wav_path = hf_hub_download(repo_id=repo_id, filename="binh_noise.wav", cache_dir='/content/voice-filter/cache')
output_wav_path = "output.wav"
mixed_wav, _ = librosa.load(mix_wav_path, sr=16000)

max_amp = np.abs(mixed_wav).max()
mix_scaling = 1 / max_amp
mixed_wav = mix_scaling * mixed_wav
mixed_wav_tf = torch.from_numpy(mixed_wav)
xvector = torch.zeros(512)
if use_gpu:
    mixed_wav_tf = mixed_wav_tf.cuda()
    xvector= xvector.cuda()

est_wav = enh_model.do_enh(mixed_wav_tf, xvector).cpu().detach().numpy()
# Normalize estimated wav
max_amp = np.abs(est_wav).max()
mix_scaling = 1 / max_amp
est_wav = mix_scaling * est_wav
# write output file
sf.write(output_wav_path, est_wav, 16000)

IPython.display.Audio(data=mixed_wav, rate=16000)

IPython.display.Audio(data=est_wav, rate=16000)

